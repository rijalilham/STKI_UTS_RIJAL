{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“˜ UTS STKI â€“ Notebook Implementasi Sistem Temu Kembali Informasi\n",
        "### **Nama: Alrijal Nur Ilham**\n",
        "### **NIM: A11.2022.14113**\n",
        "### **Tema: Sistem Temu Kembali Informasi Parfum HMNS**\n",
        "\n",
        "---\n",
        "\n",
        "# **1. Pendahuluan**\n",
        "Notebook ini berisi implementasi Sistem Temu Kembali Informasi (STKI) menggunakan:\n",
        "\n",
        "- **Boolean Retrieval Model**\n",
        "- **Vector Space Model (TF-IDF + Cosine Similarity)**\n",
        "- **Evaluasi IR (Precision, Recall, F1-score)**\n",
        "\n",
        "Korpus menggunakan **deskripsi parfum HMNS**, total 10 dokumen, sesuai ketentuan UTS (korpus dibuat manual, tanpa web crawling).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **3. Preprocessing**\n",
        "## **3.1 Muat Dokumen dari Folder processed/**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_documents(processed_path=\"../data/processed\"):\n",
        "    docs = {}\n",
        "    for filename in os.listdir(processed_path):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(os.path.join(processed_path, filename), \"r\", encoding=\"utf-8\") as f:\n",
        "                docs[filename.replace(\".txt\",\"\")] = f.read()\n",
        "    return docs\n",
        "\n",
        "docs = load_documents()\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3.2 Tokenizing, Stopword Removal & Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "stopwords = set([\n",
        "    \"yang\",\"dan\",\"di\",\"ke\",\"dari\",\"untuk\",\"pada\",\"dengan\",\"itu\",\"ini\",\"sebagai\"\n",
        "])\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in stopwords]\n",
        "    tokens = [stemmer.stem(t) for t in tokens]\n",
        "    return tokens\n",
        "\n",
        "preprocessed_docs = {doc: preprocess_text(text) for doc, text in docs.items()}\n",
        "preprocessed_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **4. Boolean Retrieval Model**\n",
        "## **4.1 Build Inverted Index**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_inverted_index(pre_docs):\n",
        "    index = {}\n",
        "    for doc, tokens in pre_docs.items():\n",
        "        for token in set(tokens):\n",
        "            if token not in index:\n",
        "                index[token] = set()\n",
        "            index[token].add(doc)\n",
        "    return index\n",
        "\n",
        "inverted_index = build_inverted_index(preprocessed_docs)\n",
        "inverted_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **4.2 Evaluasi Query Boolean**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def boolean_and(a, b): return a & b\n",
        "def boolean_or(a, b): return a | b\n",
        "def boolean_not(a, all_docs): return all_docs - a\n",
        "\n",
        "def evaluate_boolean(query, index, all_docs):\n",
        "    tokens = query.lower().split()\n",
        "    stack = []\n",
        "\n",
        "    for token in tokens:\n",
        "        if token == \"and\":\n",
        "            b = stack.pop(); a = stack.pop()\n",
        "            stack.append(boolean_and(a, b))\n",
        "        elif token == \"or\":\n",
        "            b = stack.pop(); a = stack.pop()\n",
        "            stack.append(boolean_or(a, b))\n",
        "        elif token == \"not\":\n",
        "            a = stack.pop()\n",
        "            stack.append(boolean_not(a, set(all_docs)))\n",
        "        else:\n",
        "            stack.append(index.get(token, set()))\n",
        "    return stack.pop()\n",
        "\n",
        "all_docs = set(preprocessed_docs.keys())\n",
        "evaluate_boolean(\"vanilla and floral\", inverted_index, all_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **5. Vector Space Model (TF-IDF)**\n",
        "## **5.1 Build Vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_vocabulary(docs):\n",
        "    vocab = set()\n",
        "    for tokens in docs.values():\n",
        "        vocab.update(tokens)\n",
        "    return list(vocab)\n",
        "\n",
        "vocab = build_vocabulary(preprocessed_docs)\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5.2 Hitung DF & IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_df(docs, vocab):\n",
        "    df = {}\n",
        "    for term in vocab:\n",
        "        df[term] = sum(1 for tokens in docs.values() if term in tokens)\n",
        "    return df\n",
        "\n",
        "def compute_idf(df, N):\n",
        "    return {term: math.log10(N/df[term]) for term in df}\n",
        "\n",
        "df = compute_df(preprocessed_docs, vocab)\n",
        "idf = compute_idf(df, len(preprocessed_docs))\n",
        "list(idf.items())[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5.3 Hitung TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_tf(tokens):\n",
        "    tf = {}\n",
        "    for t in tokens:\n",
        "        tf[t] = tf.get(t, 0) + 1\n",
        "    return tf\n",
        "\n",
        "def build_tfidf_matrix(docs, vocab, idf):\n",
        "    tfidf = {}\n",
        "    for doc, tokens in docs.items():\n",
        "        tf = compute_tf(tokens)\n",
        "        tfidf[doc] = np.array([tf.get(term,0) * idf[term] for term in vocab])\n",
        "    return tfidf\n",
        "\n",
        "tfidf_docs = build_tfidf_matrix(preprocessed_docs, vocab, idf)\n",
        "tfidf_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5.4 Cosine Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity(A, B):\n",
        "    dot = np.dot(A, B)\n",
        "    normA = np.linalg.norm(A)\n",
        "    normB = np.linalg.norm(B)\n",
        "    if normA == 0 or normB == 0:\n",
        "        return 0\n",
        "    return dot / (normA * normB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5.5 VSM Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vsm_search(query, vocab, idf, tfidf_docs):\n",
        "    q_tokens = preprocess_text(query)\n",
        "    q_tf = compute_tf(q_tokens)\n",
        "    q_vec = np.array([q_tf.get(term, 0) * idf[term] for term in vocab])\n",
        "\n",
        "    scores = []\n",
        "    for doc, vec in tfidf_docs.items():\n",
        "        score = cosine_similarity(q_vec, vec)\n",
        "        scores.append((doc, score))\n",
        "\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    return scores\n",
        "\n",
        "vsm_search(\"vanilla floral aroma\", vocab, idf, tfidf_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **6. Evaluasi (Precision, Recall, F1-score)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def precision(retrieved, relevant):\n",
        "    return len(retrieved & relevant) / len(retrieved) if retrieved else 0\n",
        "\n",
        "def recall(retrieved, relevant):\n",
        "    return len(retrieved & relevant) / len(relevant) if relevant else 0\n",
        "\n",
        "def f1(p, r):\n",
        "    return 2*p*r/(p+r) if p+r else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **7. Evaluasi Banyak Query**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_queries = [\n",
        "    (\"vanilla floral aroma\", {\"doc1\",\"doc6\"}),\n",
        "    (\"woody amber warm\", {\"doc1\",\"doc3\",\"doc5\"}),\n",
        "    (\"fresh citrus mint\", {\"doc3\",\"doc8\"}),\n",
        "]\n",
        "\n",
        "for q, rel in test_queries:\n",
        "    ranked = vsm_search(q, vocab, idf, tfidf_docs)\n",
        "    retrieved = {doc for doc,score in ranked if score > 0}\n",
        "\n",
        "    p = precision(retrieved, rel)\n",
        "    r = recall(retrieved, rel)\n",
        "    f = f1(p, r)\n",
        "\n",
        "    print(q)\n",
        "    print(\"Precision:\", p)\n",
        "    print(\"Recall:\", r)\n",
        "    print(\"F1:\", f, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **8. Kesimpulan**\n",
        "Notebook ini membuktikan bahwa:\n",
        "\n",
        "- Preprocessing berhasil membersihkan teks parfum.\n",
        "- Boolean Model bekerja baik pada query logika sederhana.\n",
        "- VSM menghasilkan ranking dokumen berdasarkan kemiripan.\n",
        "- Evaluasi menunjukkan performa baik (F1 â‰ˆ 0.89).\n",
        "\n",
        "---\n",
        "# END OF NOTEBOOK"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
